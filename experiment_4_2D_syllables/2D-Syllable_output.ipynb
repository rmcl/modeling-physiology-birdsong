{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419476d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52151\n"
     ]
    }
   ],
   "source": [
    "#Russell's code for extracting the data from dataset\n",
    "file_path = 'USA5288_decoded.csv'\n",
    "\n",
    "import pprint\n",
    "import re\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "#import copy\n",
    "\n",
    "def get_ordered_syllable_for_song(song_syllable_onsets_offsets_ms):\n",
    "    \"\"\"Using syllable_onsets_offsets_ms dictionary return an ordered list of tuples (syllable_label, onset, offset)\n",
    "\n",
    "    syllable_onsets_offsets_ms (dict)\n",
    "        key: syllable_label\n",
    "        value: list of tuples (onset time, offset time)\n",
    "\n",
    "    Alas python dictionaries are not ordered, so we can't rely on the order of the keys.\n",
    "    \"\"\"\n",
    "    raw_syllable_tuples = []\n",
    "    for syllable_label, times in song_syllable_onsets_offsets_ms.items():\n",
    "        for start, end in times:\n",
    "            raw_syllable_tuples.append((syllable_label, start, end))\n",
    "\n",
    "    sorted_syllable_tuples = sorted(raw_syllable_tuples, key=lambda x: x[1])\n",
    "    return sorted_syllable_tuples\n",
    "\n",
    "\n",
    "\n",
    "def get_recording_time_from_filename(recording_file_path_name):\n",
    "    \"\"\"Function to extract animal_id and convert date/time to a datetime object using named groups\"\"\"\n",
    "    try:\n",
    "        # Define the regex pattern with named groups for animal_id, month, day, hour, minute, and second\n",
    "        pattern = r'(?P<animal_id>[\\w\\d]+)_\\d+\\.\\d+_(?P<month>\\d+)_(?P<day>\\d+)_(?P<hour>\\d+)_(?P<minute>\\d+)_(?P<second>\\d+)\\.wav$'\n",
    "\n",
    "        # Search for the pattern in the file path\n",
    "        match = re.search(pattern, recording_file_path_name)\n",
    "\n",
    "        if match:\n",
    "            # Use the named groups to extract the values\n",
    "            animal_id = match.group('animal_id')\n",
    "            month = match.group('month').zfill(2)\n",
    "            day = match.group('day').zfill(2)\n",
    "            hour = match.group('hour').zfill(2)\n",
    "            minute = match.group('minute').zfill(2)\n",
    "            second = match.group('second').zfill(2)\n",
    "\n",
    "            # Construct a datetime object (assuming the year is 2024 for this example)\n",
    "            date_time_str = f\"2024-{month}-{day} {hour}:{minute}:{second}\"\n",
    "            date_time_obj = datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            return animal_id, date_time_obj\n",
    "        else:\n",
    "            return None, None  # Return None if no match is found\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def load_single_bird_syllable_csv(file_path):\n",
    "    \"\"\"\"\"\"\n",
    "    def unescape_and_eval(v):\n",
    "        if v.startswith(\"''\"):\n",
    "            v = v.replace(\"''\", \"\")\n",
    "        if v.startswith(\"'\"):\n",
    "            v = v.replace(\"'\", \"\")\n",
    "\n",
    "        return eval(v)\n",
    "\n",
    "    results = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            syllable_onsets_offsets_timebins = unescape_and_eval(row['syllable_onsets_offsets_timebins'])\n",
    "            syllable_onsets_offsets_ms = unescape_and_eval(row['syllable_onsets_offsets_ms'])\n",
    "\n",
    "            ordered_and_timed_syllables = get_ordered_syllable_for_song(syllable_onsets_offsets_ms)\n",
    "            animal_id, recording_time = get_recording_time_from_filename(row['file_name'])\n",
    "\n",
    "            data = {\n",
    "                \"file_name\": row['file_name'],\n",
    "                \"song_present\": row['song_present'],\n",
    "                #'syllable_onsets_offsets_timebins': syllable_onsets_offsets_timebins,\n",
    "                #'syllable_onsets_offsets_ms': syllable_onsets_offsets_ms,\n",
    "\n",
    "                'animal_id': animal_id,\n",
    "                'recording_time': recording_time,\n",
    "\n",
    "                'ordered_and_timed_syllables': ordered_and_timed_syllables\n",
    "            }\n",
    "\n",
    "            results.append(data)\n",
    "\n",
    "    return results\n",
    "\n",
    "def split_dataset_by_surgery_date(results, surgery_date):\n",
    "    \"\"\"Split the dataset into two groups: pre-surgery and post-surgery based on the date of surgery\"\"\"\n",
    "    results_pre_surgery = []\n",
    "    results_post_surgery = []\n",
    "\n",
    "    for result in results:\n",
    "        recording_date = result['recording_time']\n",
    "\n",
    "        if recording_date < surgery_date:\n",
    "            results_pre_surgery.append(result)\n",
    "        elif recording_date == surgery_date:\n",
    "            raise ValueError(\"Recording date is the same as the surgery date\")\n",
    "        else:\n",
    "            results_post_surgery.append(result)\n",
    "\n",
    "    return results_pre_surgery, results_post_surgery\n",
    "\n",
    "results = load_single_bird_syllable_csv(file_path)\n",
    "print(len(results))\n",
    "#pprint.pprint(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4951d748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2024, 4, 9, 0, 0), 33374, 18777)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Russell's code for splitting the dataset in pre and post-lesion data\n",
    "import json\n",
    "from datetime import datetime\n",
    "json_file_path = 'USA5288_creation_data.json'\n",
    "\n",
    "with open(json_file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    surgery_treatment_date = datetime.strptime(\n",
    "        data['treatment_date'], '%Y-%m-%d')\n",
    "\n",
    "\n",
    "results_pre_surgery, results_post_surgery = split_dataset_by_surgery_date(results, surgery_treatment_date)\n",
    "surgery_treatment_date, len(results_pre_surgery), len(results_post_surgery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7949c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establishes a set of symbols which is later used for reference\n",
    "presurgery_syllables = []\n",
    "for result in results_pre_surgery:\n",
    "    ordered_syllables = [\n",
    "        str(syl_data[0])\n",
    "        for syl_data in result['ordered_and_timed_syllables']\n",
    "    ]\n",
    "\n",
    "    if len(ordered_syllables) == 0:\n",
    "        continue\n",
    "    for i in ordered_syllables:\n",
    "        if i not in presurgery_syllables:\n",
    "            presurgery_syllables.append(i)\n",
    "\n",
    "\n",
    "#print(len(presurgery_syllables))\n",
    "##These are all of the symbols in the dataset\n",
    "#print(presurgery_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a6aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collects the durations (the differences between the end of the syllable \n",
    "#  and the beginning of the syllable) for each instance of the particular \n",
    "#  syllables to later analyze and generate a condition array (see comparisonlist below)\n",
    "diffslist = [[] for i in presurgery_syllables]\n",
    "##############################################################################PRE\n",
    "#a modified data repository to track durations and later\n",
    "#  to insert the 2D symbols in place of the 1D symbols\n",
    "symboldiffs_PRE_surgery = [[] for result in results_pre_surgery]\n",
    "#tracker keeps track of index of nested lists\n",
    "tracker = 0\n",
    "for result in results_pre_surgery:\n",
    "\n",
    "    for syl_data in result['ordered_and_timed_syllables']:\n",
    "\n",
    "        diff = syl_data[2]-syl_data[1]\n",
    "\n",
    "        #establishes the values used to measure establish the conditions\n",
    "        #  This should only be associated with pre surgery\n",
    "        diffslist[presurgery_syllables.index(str(syl_data[0]))].append(diff)\n",
    "    \n",
    "        symboldiffs_PRE_surgery[tracker].append(str(syl_data[0]))\n",
    "        symboldiffs_PRE_surgery[tracker].append(diff)\n",
    "    tracker +=1\n",
    "##############################################################################POST\n",
    "#a modified data repository to track diffs and later\n",
    "#  to insert the 2D symbols in place of the 1D symbols\n",
    "symboldiffs_POST_surgery = [[] for result in results_post_surgery]\n",
    "tracker = 0\n",
    "for result in results_post_surgery:\n",
    "\n",
    "    for syl_data in result['ordered_and_timed_syllables']:\n",
    "\n",
    "        diff = syl_data[2]-syl_data[1]\n",
    "\n",
    "    \n",
    "        symboldiffs_POST_surgery[tracker].append(str(syl_data[0]))\n",
    "        symboldiffs_POST_surgery[tracker].append(diff)\n",
    "    tracker +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74000c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [2.69841269841163, 3605.0793650793657, 1673.3337047767627, 689.6540927839395, 1400.4761904761906, 2174.920634920635]\n",
      "21 [2.6984126984125396, 4665.555555555556, 1616.4274536105524, 495.92642771812484, 1373.4920634920636, 1905.0793650793655]\n",
      "22 [2.6984126984125396, 2377.301587301588, 1238.8155907188668, 474.5012116349894, 1073.968253968254, 1513.8095238095239]\n",
      "26 [2.69841269841163, 396.6666666666667, 57.93656095259302, 35.15571391670408, 29.682539682539698, 80.95238095238165]\n",
      "23 [2.6984126984125396, 949.8412698412703, 238.80135151839795, 127.77362766917703, 121.42857142857133, 277.93650793650795]\n",
      "2 [2.6984126984125396, 1616.3492063492063, 954.4631866351984, 178.6455341734946, 879.6825396825398, 1052.3809523809525]\n",
      "3 [2.69841269841163, 4322.857142857143, 1675.8125309158943, 697.8454331567955, 1462.539682539682, 2120.9523809523807]\n",
      "5 [2.69841269841163, 2058.8888888888887, 804.6181820446238, 262.83586483711434, 666.5079365079364, 960.634920634921]\n",
      "11 [2.69841269841163, 2973.6507936507933, 807.1735950865907, 770.2906134863363, 116.03174603174557, 1594.7619047619046]\n",
      "14 [2.69841269841163, 3453.9682539682544, 825.6399650255584, 606.2154033430336, 158.5317460317459, 1317.5000000000005]\n",
      "10 [2.69841269841163, 1810.6349206349207, 584.375439031445, 641.5497603279324, 18.888888888890506, 1308.7301587301588]\n",
      "12 [2.69841269841163, 375.07936507936483, 106.90116959064329, 26.46271938388718, 97.14285714285688, 118.73015873015902]\n",
      "13 [2.69841269841163, 1300.6349206349205, 627.4795766143354, 204.67329067630658, 577.460317460318, 744.0873015873021]\n",
      "0 [2.69841269841163, 2709.20634920635, 1458.9396624313488, 319.7413014893501, 1257.460317460318, 1686.5079365079364]\n",
      "15 [2.69841269841163, 609.8412698412699, 216.61912929837462, 88.34142979796466, 205.07936507936552, 256.3492063492058]\n",
      "16 [2.69841269841163, 2425.873015873016, 861.1696467432338, 596.4264903238228, 279.2857142857142, 1316.8253968253969]\n",
      "20 [2.6984126984125396, 3240.793650793651, 1291.095435411734, 558.8443406041164, 1009.2063492063494, 1664.9206349206347]\n",
      "27 [2.69841269841163, 2460.952380952381, 693.6227824463119, 591.5190623189909, 94.44444444444446, 1204.8412698412699]\n",
      "7 [2.69841269841163, 1451.7460317460318, 472.0314364402134, 341.5810264781624, 64.76190476190504, 725.8730158730159]\n",
      "4 [2.69841269841163, 1127.936507936508, 726.4797003833447, 200.8860000087174, 639.5238095238096, 855.3968253968255]\n",
      "1 [2.6984126984125396, 6346.666666666667, 2088.241939803278, 1002.5046275347156, 1465.2380952380954, 2763.1746031746034]\n",
      "9 [2.6984126984125396, 2633.6507936507937, 1203.6212135906637, 430.18949830027253, 1084.761904761905, 1438.2539682539684]\n",
      "18 [2.698412698409811, 2353.0158730158737, 322.4878984212094, 511.9470762639003, 26.984126984127215, 178.76984126984075]\n",
      "17 [2.6984126984125396, 345.39682539682553, 120.44151680936844, 41.18831133457542, 97.14285714285734, 153.80952380952385]\n",
      "19 [2.69841269841163, 2347.6190476190477, 483.07090393588277, 516.3995825420758, 53.968253968253634, 1017.3015873015875]\n",
      "6 [2.69841269841163, 1316.8253968253975, 583.2353436226189, 366.86450823139586, 110.63492063492049, 868.8888888888887]\n",
      "25 [2.69841269841163, 1934.761904761905, 976.1344758158917, 323.94444867481326, 856.7460317460323, 1146.8253968253975]\n",
      "24 [2.6984126984125396, 736.666666666667, 424.5763361705391, 106.55130633435418, 375.07936507936415, 491.1111111111113]\n",
      "28 [2.6984126984126533, 275.2380952380952, 44.95364517488413, 40.66470622698027, 13.492063492063494, 67.46031746031747]\n",
      "29 [16.19047619047626, 124.1269841269841, 55.76719576719578, 48.53810340210467, 21.587301587301624, 75.55555555555554]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#generates the conditions array\n",
    "comparisonlist = [[] for i in presurgery_syllables]\n",
    "\n",
    "#all of this should be from the pre-surgery data exclusively\n",
    "for i in range(len(diffslist)):\n",
    "    stuff = np.array(diffslist[i])\n",
    "    #establishes the conditions\n",
    "    #minimum duration pre surgery\n",
    "    getmin = np.min(stuff)\n",
    "    #maximum duration pre surgery\n",
    "    getmax = np.max(stuff)\n",
    "    #average duration pre surgery\n",
    "    getavg = np.average(stuff)\n",
    "    #standard deviation of pre surgery duration \n",
    "    getstddev = np.std(stuff)\n",
    "    #1st quartile duration pre surgery\n",
    "    get1stqtl = np.percentile(stuff,25)\n",
    "    #3rd quartile duration pre surgery\n",
    "    get3rdqtl = np.percentile(stuff,75)\n",
    "    \n",
    "    #puts the conditions in an indexable format\n",
    "    comparisonlist[i].append(getmin)\n",
    "    comparisonlist[i].append(getmax)\n",
    "    comparisonlist[i].append(getavg)\n",
    "    comparisonlist[i].append(getstddev)\n",
    "    comparisonlist[i].append(get1stqtl)\n",
    "    comparisonlist[i].append(get3rdqtl)\n",
    "    \n",
    "#This is the list containing the min,max,avg, standard deviation,\n",
    "#  1st quartile, and 3rd quartile (bracketed numbers) for each symbol\n",
    "#  Each symbol (leftmost number) is identified based on the order of\n",
    "#  the presence in presurgery_syllables so, the values for '8' are in\n",
    "#  presurgery_syllables[0] while the values for '21' are in presurgery_syllables[1] and so on. \n",
    "for i in range(len(comparisonlist)):\n",
    "    print(presurgery_syllables[i],comparisonlist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b822ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATES CSV files containing 2D syllables appropriate for each dataset\n",
    "\n",
    "for k in symboldiffs_PRE_surgery:\n",
    "    if len(k)==0:\n",
    "        continue\n",
    "    for i in range(len(k)):\n",
    "        #makes sure to not use the difference as a symbol\n",
    "        if type(k[i]) == float:\n",
    "            continue\n",
    "        thesymbol = str(k[i])\n",
    "        comparisonindex = presurgery_syllables.index(thesymbol)\n",
    "        symbolmin = comparisonlist[comparisonindex][0]\n",
    "        symbolmax = comparisonlist[comparisonindex][1]\n",
    "        symbol1st = comparisonlist[comparisonindex][4]\n",
    "        symbol3rd = comparisonlist[comparisonindex][5]\n",
    "        \n",
    "        #defines the extra short symbol ('es' added)\n",
    "        #  intended to capture the abnormally short symbol lengths post-lesion\n",
    "        #  NOTE THAT THERE SHOULD NOT BE ANY es SYMBOLS PRE-SURGERY\n",
    "        if k[i+1] < symbolmin:\n",
    "            k[i]= '({},es)'.format(thesymbol)\n",
    "        \n",
    "        #defines the short symbol ('s' added)\n",
    "        if symbolmin <= k[i+1] < symbol1st:\n",
    "            k[i]= '({},s)'.format(thesymbol)\n",
    "        \n",
    "        #defines the long symbol ('l' added)\n",
    "        elif (symbol3rd < k[i+1] <= symbolmax):\n",
    "            k[i]= '({},l)'.format(thesymbol)\n",
    "\n",
    "        #defines the extra long symbol ('el' added)\n",
    "        #  intended to capture the abnormally long symbol lengths post-lesion\n",
    "        #  NOTE THAT THERE SHOULD NOT BE ANY el SYMBOLS PRE-SURGERY\n",
    "        elif k[i+1] > symbolmax:\n",
    "            k[i]= '({},el)'.format(thesymbol)\n",
    "\n",
    "        #defines the normal symbol ('n' added)\n",
    "        else:\n",
    "            k[i]= '({},n)'.format(thesymbol)\n",
    "\n",
    "#Now we prepare to compare the PRE, POST and Original syllable sets\n",
    "#twoD_syllables_PRE = []\n",
    "presurgerysymbols_outputprep = []\n",
    "for k in symboldiffs_PRE_surgery:\n",
    "    if len(k)==0:\n",
    "        continue\n",
    "    songlist = []    \n",
    "    for i in range(len(k)):\n",
    "        #makes sure to not use the difference as a symbol\n",
    "        if type(k[i]) == float:\n",
    "            continue\n",
    "        songlist.append(k[i])\n",
    "\n",
    "    presurgerysymbols_outputprep.append(songlist)\n",
    "\n",
    "#establishes first-half and second-half pre surgery songs\n",
    "#songnumber is the number of songs divided by 2.\n",
    "#  This may yield a float which will cause problems\n",
    "#  In order to correct this, we round up\n",
    "songnumber = len(presurgerysymbols_outputprep)/2\n",
    "#ensures songnumber is rounded up for consistency\n",
    "songnumber = int(songnumber+(songnumber % 2 > 0))\n",
    "\n",
    "\n",
    "\n",
    "#outputs the first-half pre-surgery\n",
    "fhpsfilename = 'Presurgery-songs_first-half_2D-syllables'\n",
    "with open('{}.csv'.format(fhpsfilename), 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    #writer.writerow(header)\n",
    "    for k in range(songnumber):\n",
    "        writer.writerow(presurgerysymbols_outputprep[k])\n",
    "        \n",
    "#outputs the first-half pre-surgery\n",
    "shpsfilename = 'Presurgery-songs_second-half_2D-syllables'\n",
    "with open('{}.csv'.format(shpsfilename), 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for k in range(len(presurgerysymbols_outputprep)-songnumber):\n",
    "        writer.writerow(presurgerysymbols_outputprep[k+songnumber])\n",
    "#######################################################################################\n",
    "#######################################################################################\n",
    "\n",
    "for k in symboldiffs_POST_surgery:\n",
    "    if len(k)==0:\n",
    "        continue\n",
    "    for i in range(len(k)):\n",
    "        #makes sure to not use the difference as a symbol\n",
    "        if type(k[i]) == float:\n",
    "            continue\n",
    "        thesymbol = str(k[i])\n",
    "        comparisonindex = presurgery_syllables.index(thesymbol)\n",
    "        symbolmin = comparisonlist[comparisonindex][0]\n",
    "        symbolmax = comparisonlist[comparisonindex][1]\n",
    "        symbol1st = comparisonlist[comparisonindex][4]\n",
    "        symbol3rd = comparisonlist[comparisonindex][5]\n",
    "        \n",
    "        #defines the extra short symbol ('es' added)\n",
    "        #  intended to capture the abnormally short symbol lengths post-lesion\n",
    "        if k[i+1] < symbolmin:\n",
    "            k[i]= '({},es)'.format(thesymbol)\n",
    "        \n",
    "        #defines the short symbol ('s' added)\n",
    "        if symbolmin <= k[i+1] < symbol1st:\n",
    "            k[i]= '({},s)'.format(thesymbol)\n",
    "\n",
    "        #defines the long symbol ('l' added)\n",
    "        elif (symbol3rd < k[i+1] <= symbolmax):\n",
    "            k[i]= '({},l)'.format(thesymbol)\n",
    "\n",
    "        #defines the extra long symbol ('el' added)\n",
    "        #  intended to capture the abnormally long symbol lengths post-lesion\n",
    "        elif k[i+1] > symbolmax:\n",
    "            k[i]= '({},el)'.format(thesymbol)\n",
    "\n",
    "        #defines the normal symbol ('n' added)\n",
    "        else:\n",
    "            k[i]= '({},n)'.format(thesymbol)\n",
    "\n",
    "#generates a csv with the post surgery songs\n",
    "postsurgerysymbols_outputprep = []\n",
    "for k in symboldiffs_POST_surgery:\n",
    "    if len(k)==0:\n",
    "        continue\n",
    "    #establishes a list to serve as a song to gather symbols into\n",
    "    songlist = []    \n",
    "    for i in range(len(k)):\n",
    "        #makes sure to not use the difference as a symbol\n",
    "        if type(k[i]) == float:\n",
    "            continue\n",
    "        #adds the symbol to the song\n",
    "        songlist.append(k[i])\n",
    "    #adds the song to the output list\n",
    "    postsurgerysymbols_outputprep.append(songlist)            \n",
    "#outputs the post-surgery 2D songs\n",
    "psfilename = 'Postsurgery-songs_2D-syllables'\n",
    "with open('{}.csv'.format(psfilename), 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for k in postsurgerysymbols_outputprep:\n",
    "        writer.writerow(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
